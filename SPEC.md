Papers:

Improving autoformalization via cycle consistency and incremental type-checking using language-model probabilistic programs:
https://openreview.net/pdf?id=ZGcDZ73Nb2
Neurips MATH-AI Workshop
_Mauricio Barba da Costa*_, Fabian Zaiser*, Katherine M. Collins, Romir Patel, Timothy J. Oâ€™Donnell, Alexander K. Lew, Joshua B. Tenenbaum, Vikash K. Mansinghka, Cameron E. Freer

Sequential Monte Carlo Program Synthesis with Refinement Proposals
Pre-print, under review (2025).
Maddy Bowers, _Mauricio Barba da Costa_, Xiaoyan Wang, Joshua B. Tenenbaum, Vikash K. Mansinghka, Armando Solar-Lezama, Alex K. Lew

Evaluating Language Models' Evaluations of Games:
https://arxiv.org/pdf/2510.10930
Pre-print, under review (2025).
Katherine M. Collins, Cedegao E. Zhang, Graham Todd, Lance Ying, _Mauricio Barba da Costa_, Ryan Liu, Prafull Sharma, Adrian Weller, Ionatan Kuperwajs, Lionel Wong, Joshua B. Tenenbaum, Thomas L. Griffiths

People use fast, flat goal-directed simulation to reason about novel problems
https://arxiv.org/pdf/2510.11503?
Pre-print, under review (2025).
Katherine M. Collins*, Cedegao E. Zhang*, Lionel Wong*, _Mauricio Barba da Costa*_, Graham Todd, Adrian Weller, Samuel J. Cheyette, Thomas L. Griffiths, and Joshua B. Tenenbaum

Talks:
Automatic Geometry Theorem Proving Using Polynomial Elaboration
https://leanprover-community.github.io/itp-2025-lean-workshop/
ITP 2025 Lean Workshop
[Slides](GenLean.pdf)

Disambiguating natural language with probabilistic inference
https://europroofnet.github.io/MCLP/
International Conference on Mathematical and Computational Linguistics for Proofs (MCLP 2025)

Bio:
I'm an MEng student at MIT advised by Josh Tenenbauma and Vikash Mansinghka. I'm interested in probabilistic inference, program synthesis, and making language models more efficient.
